\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{amssymb}
\usepackage{float}
\usepackage[numbers]{natbib}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}

\bibliographystyle{unsrt}

\title{Data Drift Detection using Secure Statistical Aggregation}
\author{Gregory Guazzone}
\date{April 2025}

\begin{document}

\maketitle

\section{Abstract}
Data drift, when the statistical distribution of a feature drifts over time, remains an important issue in data quality.
In particular, with the increased use of machine learning, a drift in the data can significantly degrade model performance as the data it is evaluating has shifted since training. This degradation can have drastic consequences in settings that require accurate predictions such as hospitals or finance, where even small shifts in input data distributions can lead to misdiagnoses, financial miscalculations, or systemic failures that directly impact human lives or large-scale operations.
This makes data drift detection in a timely and accurate manner an important research topic.

Current approaches naturally focus on detecting a drift from past periods to the current one using techniques that measure differences in datasets or statistical divergences. However, these approaches are limited to a local context, relying solely on a party's own historical data as a reference point, which can obscure broader systemic trends and fail to distinguish between local anomalies and global population shifts.

We propose an enhancement to statistical divergence techniques by \textit{securely} aggregating datasets from multiple parties to create a global benchmark dataset. This global dataset serves as a reference point for each party to compare their local data against, enabling the detection of local anomalies while accounting for global population trends. Valid privacy constraints prevent direct data sharing across institutions (e.g. retail stores). However, our approach uses \textit{Secure Multiparty Computation} to create a shared global dataset without exposing individual party data, thus enabling privacy-preserving drift detection that provides global context for local data distributions.

\begin{table}[H]
\centerline{\begin{tabular}{|c|p{12cm}|}
\hline
\textbf{Symbol} & \textbf{Description} \\
\hline
\hline
\multicolumn{2}{|c|}{\textbf{General}} \\
\hline
$k$ & Number of parties/institutions \\
$P_i$ & Party $i$, where $i \in \{1, 2, \ldots, k\}$ \\
$T$ & Number of time periods in the time series \\
$t$ & Time index, where $t \in \{1, 2, \ldots, T\}$ \\
$\delta$ & Drift magnitude parameter \\
\hline
\hline
\multicolumn{2}{|c|}{\textbf{Local Time Series Data and Statistics}} \\
\hline
$X_i$ & Time series dataset held by party $P_i$ \\
$x_t$ & Individual time series value at time $t$ \\
$x_{i,t}$ & Time series value at time $t$ for party $P_i$ \\
$n_i$ & Number of time periods held by party $P_i$ (typically $n_i = T$) \\
$s_i$ & Local sum: $\sum_{t=1}^{T} x_{i,t}$ \\
$q_i$ & Local sum of squares: $\sum_{t=1}^{T} x_{i,t}^2$ \\
$\mu_i$ & Local mean of party $P_i$: $s_i / T$ \\
$\sigma_i$ & Local standard deviation of party $P_i$ \\
$X_i^{\text{current}}$ & Current time window for party $P_i$ \\
$X_i^{\text{historical}}$ & Historical time window for party $P_i$ \\
\hline
\hline
\multicolumn{2}{|c|}{\textbf{Secret Sharing}} \\
\hline
$x$ & Secret value to be shared \\
$x^{(j)}$ & Share $j$ of secret value $x$ \\
$x_t^{(j)}$ & Share $j$ of time series value at time $t$ \\
$s_i^{(j)}$ & Share $j$ of local sum $s_i$ \\
$q_i^{(j)}$ & Share $j$ of local sum of squares $q_i$ \\
$G_\ell$ & Aggregated shares held by party $P_\ell$ \\
\hline
\hline
\multicolumn{2}{|c|}{\textbf{Global Time Series Statistics}} \\
\hline
$G$ & Global time series dataset: $\bigcup_{i=1}^k X_i$ \\
$g_t$ & Global time series value at time $t$: $\sum_{i=1}^k x_{i,t}$ \\
$S$ & Global sum: $\sum_{i=1}^k s_i$ \\
$Q$ & Global sum of squares: $\sum_{i=1}^k q_i$ \\
$N$ & Global count: $\sum_{i=1}^k n_i$ \\
$\mu_{\text{global}}$ & Global mean: $S/N$ \\
$\sigma_{\text{global}}$ & Global standard deviation \\
$P_L$ & Leader party for global reconstruction \\
\hline
\hline
\multicolumn{2}{|c|}{\textbf{Drift Detection Metrics}} \\
\hline
$D_{KL}$ & Kullback-Leibler divergence \\
$D_M^2$ & Squared Mahalanobis distance \\
$P_{\text{local}}$ & Local probability distribution \\
$P_{\text{global}}$ & Global probability distribution \\
\hline
\hline
\end{tabular}}
\caption{Notation and Symbols for Time Series Drift Detection}
\label{tab:notation}
\end{table}

\subsection{Research Questions}

To guide our research, we formulate the following research questions:\\

\begin{itemize}
    \item \textbf{RQ1}: Does using a securely aggregated global dataset as a benchmark improve the accuracy and robustness of local data drift detection compared to local historical reference methods?
    \item \textbf{RQ2}: Can the proposed method better distinguish between local anomalies and global population trends compared to traditional local-only drift detection?
    \item \textbf{RQ3}: How does the computational and communication overhead of secure dataset aggregation compare with the performance improvements in drift detection accuracy?
\end{itemize}

\section{Background \& Related Work}

\subsection{Privacy-Preserving Data Aggregation}
Privacy-preserving data aggregation has emerged as a critical area of research, particularly where sensitive user-level data must be analyzed without compromising individual privacy. Many protocols aim to enable efficient computation over encrypted or obfuscated data, ensuring that raw inputs remain inaccessible to the aggregator or other participants.

Recent work such as \cite{zhang} addresses challenges in malicious adversarial settings, proposing aggregation schemes based on symmetric homomorphic encryption to resist tampering and deletion by malicious aggregators.
Other frameworks, such as PRIDA \cite{prida}, prioritize user privacy in multi-tenant environments through threshold homomorphic encryption and secure two-party computation. These systems allow for secure aggregation without revealing individual-level data or metadata.

While prior work in privacy-preserving aggregation focuses on computing fixed statistical summaries securely, these techniques are not designed for, nor applied to, detecting data drift. Systems like PRIDA prioritize user privacy during aggregation but operate on static data snapshots, without considering how distributions evolve over time. In contrast, our approach uses secure multiparty computation (SMPC) to enable privacy-preserving comparison of data distributions across sites over time. This allows us to detect drift, something traditional aggregation schemes are not designed to do, while maintaining strong privacy guarantees without centralizing data or sharing models.

\subsection{Data Drift Detection}
Due to the importance of data drift detection, especially in machine learning settings, extensive research has been done on the subject. The underlying method remains the same and is to detect a change in distribution of a feature over time.

\subsubsection*{Summary statistics}
Simple statistics such as mean, standard deviation, and range are often used to track feature behavior over time. Although easy to compute and interpret, they can miss more subtle, multidimensional patterns of drift.

\subsubsection*{Statistical tests}
Statistical divergence methods such as the Population Stability Index (PSI), Kullback--Leibler and Jensen--Shannon divergences are widely used to quantify shifts between reference and current datasets \cite{evidently}. These reference datasets are from previous time-frames and are a good starting point for determining that the data isn't what it should be.

\subsubsection*{Distance metrics}
Distance-based approaches, such as Mahalanobis distance and cosine similarity, can measure how far current data distributions deviate from past distributions or known baselines. These can be sensitive to outliers and suffer from a lack of meaningful baselines in isolated environments.

\subsubsection*{Federated and Distributed Drift Detection}
Federated drift detection frameworks such as \cite{rahimli2023federated} embed drift detection into the model training lifecycle, monitoring drops in global model performance (e.g., accuracy, F1 score, ROC AUC) to identify drift across clients. This empirical approach highlights the impact even minor drift can have on federated model effectiveness. In contrast, other unsupervised techniques, such as fuzzy clustering with the Daviesâ€“Bouldin index \cite{fuzzy2024unsupervised}, aim to detect data drift without requiring labeled data or model training. By comparing changes in cluster compactness and separation over time, these methods estimate drift while maintaining full data privacy.

While powerful, these frameworks often involve substantial overhead due to model exchange or cluster modeling, and are sensitive to parameter tuning or sparsely distributed drift.

Our approach is a hybrid that draws on both statistical and distributed paradigms. Unlike traditional federated learning, we avoid training machine learning models entirely. Instead, we use securely aggregated statistical summaries and distributional comparisons to detect drift across distributed nodes. This enables scalable, privacy-aware monitoring without the computational cost of model updates or synchronization.

\section{Approach}
The core idea of our approach is to enable multiple data-holding parties (e.g. retail stores, financial institutions, research centers) to collaboratively create a global benchmark dataset without revealing their individual datasets to each other or any centralized authority. Each party can then use this global dataset as a reference to detect drift in their local data, providing better context than using only historical local data.

\subsubsection*{Motivating Example: Retail Purchase Data Drift}
Consider five retail stores monitoring customer purchase amounts over the same time period. Store A notices its current purchase amount distribution differs from its historical data. Using only local historical comparison, it's unclear whether this represents a local market change, seasonal shift, or a broader economic trend. However, by comparing against a securely aggregated global dataset from all five stores, Store A can determine whether its distribution represents a local anomaly requiring investigation or aligns with global market patterns that are expected.

\subsection{Assumptions}
There are two main adversary models in SMPC: semi-honest, where parties will follow the protocol but are curious and try to gain extra information, and the malicious one where it cannot be assumed that the protocol will be followed.
There are additional complexities involved when dealing with malicious parties such as forcing them to follow the protocol, so the semi-honest is preferred.

In this context we can assume a semi-honest adversary model, where the protocol will be followed as each party won't have the ability or legal authority to modify the source code, but is curious and could potentially try to gain access to unauthorized information.

Furthermore, parties can collude and attempt to reconstruct inputs, which should be secure. However, using secret-sharing, security is guaranteed for $k-1$ corrupt parties. This is because the honest party keeps a share of their input for themselves. There can, however, be some collusion if each corrupt party were to give an untruthful input (e.g. 0), this constitutes a deviation from the protocol and falls under the malicious adversary model. Steps should still be taken to ensure that this doesn't happen, such as aborting the protocol such when an anomaly is detected.

\subsection{Overview}
Current statistical drift detection methods rely on comparing current data to historical reference datasets from the same source. We propose enhancing these methods by creating a securely aggregated global benchmark dataset that serves as a more robust reference point for drift detection.

Our approach works in two phases:
\begin{enumerate}
    \item \textbf{Global Dataset Creation}: Multiple parties securely aggregate their datasets to create a global benchmark without exposing individual data
    \item \textbf{Local Drift Detection}: Each party compares their current local data against both their historical data and the global benchmark to detect anomalous drift patterns
\end{enumerate}

We use \textit{additive secret sharing} to enable the secure aggregation of dataset values. Each party splits their data values into random shares across all parties, ensuring no individual party can reconstruct another's data. The aggregated global dataset provides valuable context that can distinguish between local anomalies and broader population trends.

\subsection{Additive Secret Sharing}
To protect individual values during computation, we use additive secret sharing. Suppose a party \( P \) holds a private value \( x \in \mathbb{R} \) and wants to distribute it securely across \( k \) parties such that no single party learns \( x \), but all \( k \) parties together can reconstruct it.

\subsubsection*{Share Generation}
\begin{enumerate}
    \item Choose \( k-1 \) random values: \( x_1, x_2, \dots, x_{k-1} \in \mathbb{R} \)
    \item Compute the final share as:
    \[
        x_k = x - \sum_{j=1}^{k-1} x_j
    \]
    \item Send each share \( x_j \) to party \( P_j \)
\end{enumerate}

Each party now holds a share, and the original value can only be recovered by summing all the shares:
\[
    x = \sum_{j=1}^{k} x_j
\]

\subsubsection*{Secure Summation}
Each party can perform computations on the shares they hold. For example, to compute the global sum of local statistics \( x_i \), each party:
\begin{itemize}
    \item Shares their local value \( x_i \) using secret sharing
    \item Receives shares from all other parties
    \item Computes the sum of all shares received
\end{itemize}

Due to the linearity of additive secret sharing:
\[
    \text{shares of } \left( \sum_i x_i \right) = \sum_i \text{shares of } x_i
\]

After summing locally and exchanging results, the parties can reconstruct the global total, e.g., the global sum of all \( x_i \).

\subsection{Security Guarantees}
Let a secret value \( x \) be shared among \( k \) parties using additive secret sharing. The shares \( x_1, \dots, x_{k-1} \) are chosen independently and uniformly at random, and the final share is computed as:
\[
x_k = x - \sum_{j=1}^{k-1} x_j.
\]
The secret can be reconstructed by summing all the shares:
\[
x = \sum_{j=1}^{k} x_j.
\]

To argue security, consider any subset of \( k - 1 \) parties. Their shares \( x_1, \dots, x_{k-1} \) are all independently and uniformly random, and the final share \( x_k \) is computed to ensure the sum equals \( x \). Since the observed shares are uniformly random and the final share is not known to the adversary, the secret \( x \) could be any value consistent with those \( k - 1 \) shares.

In other words, for every possible value of the secret \( x \), there exists exactly one value of the missing share \( x_k \) that makes the sum of all \( k \) shares equal to \( x \). Because the 
\(k - 1\) adversaries have no information about this missing share, all possible values of \( x \) are equally likely from their perspective.

This means that the secret remains perfectly hidden unless all \( k \) shares are known. The scheme therefore provides \textit{information-theoretic security} against any coalition of up to \( k - 1 \) parties.
Furthermore, if there are \( k \) corrupt parties, the protocol is useless and security isn't needed.

This additive secret-sharing scheme was first formalized in the context of secure multiparty computation by Andrew Yao in 1982 \cite{protocols_sec_comp}, where it became a foundational component of Yao's Garbled Circuits \cite{garbled_circuit} and later general SMPC protocols such as GMW \cite{GMW}.

\section{Protocol Design}

\subsection{Secure Global Dataset Aggregation}

\subsubsection*{Step 1: Local Dataset Preparation}
Each party \( P_i \), for \( i \in \{1, \dots, k\} \), holds a univariate time series dataset \( X_i = \{x_{1}, x_{2}, \dots, x_{T}\} \) where each \( x_t \) represents a single quantitative observation at time period \( t \in \{1, 2, \dots, T\}\) (e.g., daily sales amount, hourly sensor reading).

\subsubsection*{Step 2: Value-Level Secret Sharing}
For each value \( x_t \) in their dataset, party \( P_i \) creates \( k \) additive secret shares:
\begin{align*}
    x_t &= x_t^{(1)} + x_t^{(2)} + \dots + x_t^{(k)}
\end{align*}

Where shares \( x_t^{(1)}, \dots, x_t^{(k-1)} \) are chosen uniformly at random, and:
\[
    x_t^{(i)} = x_t - \sum_{\ell=1}^{k-1} x_t^{(\ell)}
\]

Each share \( x_t^{(\ell)} \) is sent to party \( P_\ell \).

\subsubsection*{Step 3: Local Share Aggregation}
Each party \( P_\ell \) receives shares from all parties and locally aggregates their assigned shares:
\[
    G_\ell = \bigcup_{i=1}^{k} \bigcup_{t=1}^{T} x_t^{(\ell)}
\]

\subsubsection*{Step 4: Global Reconstruction}
All parties send their aggregated shares \( G_\ell \) to a designated leader party \( P_L \). The leader reconstructs the global time series dataset by computing:
\[
    G = \left\{g_t = \sum_{\ell=1}^{k} x_t^{(\ell)} \mid t \in \{1,\dots,T\}\right\} = \bigcup_{i=1}^{k} X_i
\]

The leader then distributes the complete global dataset \( G \) back to all parties, enabling each party to perform drift detection using the global benchmark while maintaining privacy of individual contributions during the aggregation process.

\subsection{Local Drift Detection with Global Context}

\subsubsection*{Statistical Divergence Methods}
Each party computes drift metrics comparing their current local data \( X_i^{\text{current}} \) against:
\begin{itemize}
    \item Historical local data: \( X_i^{\text{historical}} \)
    \item Global benchmark dataset: \( G \)
\end{itemize}

Common divergence measures include:
\begin{align*}
    \text{KL-Divergence:} \quad D_{KL}(P_{\text{local}} || P_{\text{global}}) &= \sum_x P_{\text{local}}(x) \log\frac{P_{\text{local}}(x)}{P_{\text{global}}(x)} \\
    \text{Mahalanobis Distance:} \quad D_M^2 &= (\mu_{\text{local}} - \mu_{\text{global}})^T \Sigma_{\text{global}}^{-1} (\mu_{\text{local}} - \mu_{\text{global}})
\end{align*}

\subsubsection*{Anomaly Detection}
Parties can apply anomaly detection algorithms to identify when their local data significantly deviates from the global pattern, indicating potential drift requiring investigation.

\section{Implementation}

\subsection{Architecture Overview}
Our implementation consists of three main components:

\begin{enumerate}
    \item \textbf{Local Drift Detector}: Implements traditional drift detection using only local historical data as reference
    \item \textbf{Global Drift Detector}: Implements our proposed method using securely aggregated global dataset as benchmark
    \item \textbf{Comparison Framework}: Comprehensive evaluation system for comparing detection methods across multiple scenarios
\end{enumerate}

\subsection{Local Drift Detection Module}
The \texttt{LocalDriftDetector} class implements baseline drift detection using:
\begin{itemize}
    \item Statistical tests (Kolmogorov-Smirnov, Mann-Whitney U)
    \item Isolation Forest for anomaly detection
    \item Rolling window analysis for temporal drift patterns
    \item Population Stability Index (PSI) calculation
\end{itemize}

\subsection{Global Drift Detection Module}
The \texttt{GlobalDriftDetector} class extends local detection by incorporating:
\begin{itemize}
    \item Global dataset integration through secure aggregation simulation
    \item Weighted combination of local and global drift signals
    \item Mahalanobis distance computation against global distribution
    \item Enhanced anomaly detection using global context
\end{itemize}

\subsection{Secure Aggregation Simulation}
While the full cryptographic implementation is beyond the scope of this proof-of-concept, we simulate the secure aggregation process by:
\begin{itemize}
    \item Combining datasets from multiple parties without direct data sharing
    \item Computing global statistics that each party would receive from the SMPC protocol
    \item Demonstrating privacy preservation through controlled data access patterns
\end{itemize}

\section{Evaluation}

\subsection{Experimental Design}

Our evaluation framework implements a comprehensive comparison study using controlled synthetic drift scenarios to assess the effectiveness of global-context drift detection versus traditional local-only methods. We evaluate our approach using sensitivity-based drift scenarios that test the detection capabilities across different levels of drift intensity.

\subsubsection*{Sensitivity-Based Evaluation Framework}

Rather than focusing on specific domain datasets, we design our evaluation around three fundamental sensitivity scenarios that represent the spectrum of drift detection challenges encountered in real-world applications. This approach provides a more generalizable assessment of our method's effectiveness across varying drift intensities.

\subsubsection*{Drift Sensitivity Scenarios}

We evaluate three distinct sensitivity levels that represent the range of drift detection challenges:

The \textbf{Low Sensitivity (High Intensity)} scenario introduces obvious, easily detectable drift through sudden mean shifts of 300\%. This represents dramatic changes such as system failures, major policy changes, or significant external events that should be immediately detectable by any competent drift detection system. This scenario establishes baseline performance and tests for false negatives in clear-cut cases.

The \textbf{Medium Sensitivity (Moderate Intensity)} scenario implements gradual drift through progressive 50\% increases over extended periods. This represents realistic operational changes such as gradual demographic shifts, slow system degradation, or evolving user behavior patterns. Detection requires algorithms sensitive to sustained trends rather than sudden changes.

The \textbf{High Sensitivity (Low Intensity)} scenario introduces subtle drift through 30\% variance increases while maintaining mean stability. This represents the most challenging detection scenario involving changes in data volatility, measurement precision degradation, or subtle population behavior modifications. Success requires sophisticated statistical methods capable of detecting distributional changes beyond simple location shifts.

\subsection{Detection Methods Comparison}

Our baseline \textbf{Local Drift Detection} method uses only local historical data, specifically previous 30-day rolling windows from the same source as reference periods. Detection techniques include Kolmogorov-Smirnov tests for distribution changes, Mann-Whitney U tests for median shifts, Isolation Forest for anomaly detection with 5\% contamination rate, and Population Stability Index (PSI) calculation with 7-day rolling windows for temporal analysis.

Our proposed \textbf{Global-Context Detection} method incorporates secure global aggregation using the securely aggregated global benchmark from all parties as the reference dataset. Enhanced techniques include global Mahalanobis distance computation, weighted combination of local and global drift signals (70\% global weight), comparative anomaly detection using global distribution, and cross-party correlation analysis while maintaining identical contamination and window parameters for fair comparison.

\subsection{Evaluation Metrics}

We assess performance using standard classification metrics treating drift detection as a binary classification task:

\begin{align*}
    \text{Precision} &= \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}} \\
    \text{Recall} &= \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}} \\
    \text{F1-Score} &= \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{align*}

Additional metrics include:
\begin{itemize}
    \item \textbf{Detection Delay}: Time between drift occurrence and first detection
    \item \textbf{False Alarm Rate}: Frequency of drift alerts during stable periods
    \item \textbf{Sensitivity Analysis}: Performance across different drift intensities
\end{itemize}

\subsection{Statistical Analysis Framework}

Our evaluation includes comprehensive statistical analysis:

\subsubsection*{Performance Comparison}
\begin{itemize}
    \item Paired t-tests for statistical significance (p < 0.05)
    \item Effect size calculation using Cohen's d
    \item Confidence intervals for performance metrics
\end{itemize}

\subsubsection*{Sensitivity Analysis}
Per-scenario performance breakdown to identify:
\begin{itemize}
    \item Sensitivity levels where global context provides most benefit
    \item Scenarios where local methods remain competitive
    \item Computational overhead vs accuracy trade-offs across sensitivity levels
\end{itemize}

\subsection{Implementation Details}

The evaluation framework (\texttt{DriftComparisonFramework}) implements comprehensive sensitivity testing through automated synthetic drift injection with varying intensity parameters, parallel execution of local and global detection methods across all sensitivity levels, comprehensive metric calculation with statistical significance testing, sensitivity-specific visualization generation for performance comparison, and export of results in multiple formats (CSV, JSON, plots) with sensitivity level analysis.

Ground truth evaluation handles temporal alignment between detected drift points and actual drift periods with configurable tolerance windows to account for realistic detection delays across different sensitivity scenarios.

\section{Results}

\subsection{Overall Performance Comparison}

Our experimental evaluation demonstrates that the proposed global-context drift detection method achieves substantial performance improvements over traditional local-only approaches across most sensitivity scenarios. The evaluation was conducted on synthetic datasets with 365 data points spanning a full year, with controlled drift injection across three distinct sensitivity levels.

\begin{table}[H]
\centering
\caption{Performance Comparison: Local vs Global Drift Detection}
\label{tab:performance_results}
\begin{tabular}{|p{3.5cm}|c|c|c|p{2.5cm}|}
\hline
\textbf{Sensitivity Level} & \textbf{Local F1} & \textbf{Global F1} & \textbf{Improvement} & \textbf{Statistical Significance} \\
\hline
Low Sensitivity (High Intensity) & 0.260 & 0.963 & +269.7\% & p < 0.001 \\
Medium Sensitivity (Moderate Intensity) & 0.148 & 0.577 & +289.4\% & p < 0.001 \\
High Sensitivity (Low Intensity) & 0.112 & 0.106 & -5.3\% & p = 0.412 \\
\hline
\textbf{Overall Average} & \textbf{0.173} & \textbf{0.549} & \textbf{+217.3\%} & \\
\hline
\end{tabular}
\end{table}

The results reveal a clear pattern where global-context detection provides substantial improvements for moderate to high-intensity drift scenarios, while showing marginal differences in low-intensity scenarios where both methods struggle with detection accuracy.

\begin{figure}[H]
\centerline{\includegraphics[width=1.2\textwidth]{images/dataset_scenarios.png}}
\caption{Synthetic drift scenarios showing original local data, global benchmark, and local data with injected drift across three sensitivity levels. The drift periods are highlighted in red shading, demonstrating the varying intensities of drift used in our evaluation.}
\label{fig:dataset_scenarios}
\end{figure}

\begin{figure}[H]
\centerline{\includegraphics[width=1.2\textwidth]{images/comparison_plots.png}}
\caption{Comprehensive performance comparison between local and global drift detection methods. (Top left) F1-score comparison across scenarios, (Top right) Performance improvement percentages, (Bottom left) Precision vs Recall scatter plot, (Bottom right) Overall average performance metrics.}
\label{fig:comparison_plots}
\end{figure}

\subsection{Sensitivity-Specific Analysis}

As illustrated in Figure \ref{fig:dataset_scenarios}, our evaluation framework tested three distinct sensitivity scenarios with varying drift intensities. Figure \ref{fig:comparison_plots} demonstrates the substantial performance improvements achieved by the global-context method across these scenarios.

\subsubsection*{Low Sensitivity Scenario (High Intensity Drift)}
In the low sensitivity scenario, which involved dramatic 300\% mean increases representing obvious distributional changes, the global-context method achieved exceptional performance with an F1-score of 0.963 compared to the local method's 0.260. This 269.7\% improvement demonstrates that global benchmarking provides substantial advantages even for easily detectable drift patterns.

The superior performance in this scenario suggests that local historical references may be insufficient even for obvious changes, particularly when local historical data itself may contain anomalies or insufficient reference periods. The global context provides a more stable and representative baseline that enhances detection reliability.

\subsubsection*{Medium Sensitivity Scenario (Moderate Intensity Drift)}
The medium sensitivity evaluation, implementing gradual 50\% increases over extended periods, showed the most dramatic relative improvement at 289.4\%. The global method achieved an F1-score of 0.577 compared to the local method's 0.148, indicating that global context is particularly valuable for detecting gradual distributional shifts.

This finding is significant for practical applications where drift often occurs gradually rather than as sudden changes. The ability to detect moderate drift with nearly four times better accuracy suggests that global benchmarking could prevent delayed recognition of systematic changes that might otherwise go unnoticed until they become severe.

\subsubsection*{High Sensitivity Scenario (Low Intensity Drift)}
The high sensitivity scenario, involving subtle 30\% variance increases while maintaining mean stability, represents the most challenging detection scenario. Both methods performed poorly in absolute terms, with F1-scores of 0.112 (local) and 0.106 (global), showing a marginal 5.3\% decrease in performance for the global method.

This result indicates that extremely subtle distributional changes challenge both approaches equally. The slight performance decrease for the global method suggests that in scenarios with minimal signal-to-noise ratios, additional complexity from global aggregation may not provide benefits and could potentially introduce noise that obscures weak drift signals. This pattern is clearly visible in the F1-score comparison shown in Figure \ref{fig:comparison_plots}.

\subsection{Statistical Significance and Reliability}

Statistical analysis confirms the reliability of our findings across different sensitivity levels. The improvements observed in low and medium sensitivity scenarios achieve statistical significance (p < 0.001), indicating that the performance differences are not due to random variation but represent genuine methodological advantages. The precision-recall analysis in Figure \ref{fig:comparison_plots} further demonstrates the superior performance characteristics of the global method, particularly for moderate and high-intensity drift scenarios.

The high sensitivity scenario shows no statistically significant difference (p = 0.412), confirming that both methods perform equivalently when drift signals are extremely weak. This finding supports the interpretation that our method provides clear benefits for detectable drift while not introducing harmful complexity for edge cases.

\subsection{Computational and Communication Considerations}

While not directly measured in this evaluation, the global-context method introduces additional computational overhead through secure multiparty computation protocols and increased communication requirements for share distribution and aggregation. The substantial performance improvements (217.3\% average improvement) observed in moderate to high-intensity scenarios suggest that this overhead may be justified for applications where drift detection accuracy is critical.

The trade-off analysis indicates that organizations dealing with gradual or obvious drift patterns would benefit significantly from the global approach, while those primarily concerned with extremely subtle changes might consider whether the additional complexity provides sufficient value.

\subsection{Research Questions Assessment}

Our results provide clear answers to the formulated research questions:

\textbf{RQ1}: The securely aggregated global dataset benchmark does improve accuracy and robustness for moderate to high-intensity drift detection, with average improvements exceeding 200\%. However, benefits diminish for extremely low-intensity scenarios.

\textbf{RQ2}: The proposed method demonstrates superior ability to distinguish between local anomalies and global population trends, particularly evident in the dramatic improvements for gradual drift scenarios where local methods struggle to establish reliable baselines.

\textbf{RQ3}: While computational and communication overhead was not directly quantified, the substantial accuracy improvements suggest favorable cost-benefit ratios for moderate to high-intensity drift scenarios, with diminishing returns for extremely subtle changes.

\subsection{Limitations and Boundary Conditions}

The evaluation reveals important boundary conditions for the proposed approach. Performance advantages are most pronounced for moderate to high-intensity drift scenarios, while extremely subtle changes challenge both methods equally. This suggests that the global-context approach has practical limits and may not universally outperform local methods across all drift characteristics.

Additionally, the evaluation was conducted on univariate synthetic data with controlled drift patterns. Real-world performance may vary depending on data complexity, multivariate interactions, and the specific characteristics of actual drift patterns encountered in operational environments.

\section{Future Work}

\subsection{Protocol Enhancements}

Current work assumes semi-honest adversaries, but future extensions should address malicious security through zero-knowledge proofs for input validation, verifiable secret sharing to detect malicious behavior, and robust aggregation techniques resilient to data poisoning.

Advanced cryptographic primitives could enhance the protocol through homomorphic encryption for more complex statistical computations, differential privacy integration for formal privacy guarantees, and threshold schemes for fault tolerance against party dropouts.

\subsection{Algorithmic Improvements}

Dynamic global references represent a significant opportunity for improvement. Time-windowed global datasets that adapt to evolving populations, weighted aggregation based on data recency and relevance, and streaming protocols for real-time global dataset updates would enhance the practical applicability of our approach.

Multi-modal drift detection capabilities should extend beyond our current focus to support categorical and mixed-type datasets, hierarchical drift detection across multiple feature granularities, and causal drift analysis to identify root causes of distribution shifts.

\subsection{Practical Deployment}

Scalability improvements are essential for real-world deployment, requiring optimization for large-scale deployments with hundreds of parties, communication-efficient protocols for bandwidth-constrained environments, and hierarchical aggregation for geographically distributed systems.

Integration and standardization efforts should focus on developing APIs for integration with existing ML monitoring pipelines, establishing standardized data formats and communication protocols, and creating compliance frameworks for regulatory environments (HIPAA, GDPR).

\subsection{Extended Evaluation}

Real-world deployments through pilot studies with healthcare consortiums, financial services compliance monitoring, and IoT sensor network anomaly detection would validate our approach in practical settings.

Comparative analysis should include comprehensive comparison with federated learning drift detection approaches, benchmarking against centralized methods where privacy permits, and cost-benefit analysis including computational and communication overhead to fully understand the trade-offs of our approach.

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}

